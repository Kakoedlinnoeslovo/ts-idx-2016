{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании мы будем строить саммари из текста, используя алгоритм LexRank (https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "import nltk.data\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим документы из файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for file in os.listdir(data_dir):\n",
    "    file_name = data_dir + '/' + file\n",
    "    with open(file_name) as f:\n",
    "        data = f.read()\n",
    "        documents.append(data.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят документы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bob Livingston, the incoming speaker of the House, took no public role Friday as the debate unfolded on whether to impeach President Clinton. His previous 24 hours had been his most visible in the month since his party nominated him as speaker and perhaps the most excruciating in his public career: He spent most of the day in a chaotic procedural wrangle over the terms of Friday's debate; he ended it by telling his Republican colleagues that he had had extramarital affairs during his 20-year tenure in Congress. His disclosure followed an investigation by Larry Flynt, publisher of Hustler, the sex magazine, who said Friday at a news conference in Beverly Hills, Calif., that his publication had learned that Livingston had had adulterous affairs during the last 10 years. Flynt said earlier this year that he wanted to expose the ``hypocrisy'' of those in Washington who are investigating Clinton and in October offered $1 million to anyone who could prove they had had affairs with members of Congress. He said Friday that this larger investigation, to be published perhaps as soon as January, would reveal what he described as indiscretions of several other Republicans. He said he had no connection with the White House but that he had hired an investigative firm based in Washington and made up of former employees of the FBI and the CIA. He would not confirm whether the firm is Terry Lenzner's Investigative Group Inc., which has done work for the president's private lawyers. Livingston was unavailable to reporters Friday. He spent some time Friday morning sprawled in a chair in the back of the House chamber, listening to the debate over whether to impeach Clinton for lying about his own sexual indiscretions. Several colleagues knelt at Livingston's knee, whispered to him and patted him on the back. He spent most of the day in a private office off the chamber, avoiding the gauntlet of reporters who lay in wait for him between the House and his regular office across the street. The only word out of his aides was that the Navy had awarded contracts worth millions of dollars for ships to be built in his Louisiana district at the Avondale Shipyards. During Friday's debate, a handful of Democrats made only oblique allusions to human failures. For example, Rep. John Lewis, D-Ga., said: ``Let he that has no sin cast the first stone. Who, who among us has not sinned?'' But no one said that Livingston's disclosure or the mild Democratic attempts to exploit it would influence their votes on impeachment. Rather, on the House floor and in hallway chitchat, Livingston's conduct seemed to be the last thing that either Republicans or Democrats wanted to talk about. ``Bob Livingston is a first-rate human being,'' said Rep. David Obey, D-Wis., who has worked closely and sparred with Livingston on the Appropriations Committee, in an interview. ``I will repeat what the nuns taught me at St. James a long time ago: We would all be a hell of a lot better off looking after our own souls rather than trying to evaluate somebody else's. None of us have any business even having an opinion on it.'' Even conservative Republicans seemed ready to overlook the disclosure. ``We're not going to say, `Bob, you can't be speaker because you violated your vows with your wife,''' said Rep. Lindsey Graham, R-S.C. Like many, including Livingston, Graham distinguished Livingston's conduct from Clinton's by saying that the president had ``trampled'' on the legal system whereas Livingston's behavior was strictly private. Despite Flynt's claims, many Republicans blamed the Clinton administration for smearing Livingston, although they offered no evidence. ``This isn't just happening on its own,'' said Rep. Dana Rohrabacher, R- Calif.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(doc):\n",
    "    \"\"\"\n",
    "    Get sentences from document\n",
    "\n",
    "    Inputs:\n",
    "    - text: string\n",
    "\n",
    "    Returns:\n",
    "    - list of sentences\n",
    "    \"\"\"\n",
    "    list_sentences = doc.split('.')\n",
    "        \n",
    "    \n",
    "    \n",
    "    return list_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decorators\n",
    "def to_utf8(text):\n",
    "    if isinstance(text, unicode): text = text.encode('utf8')\n",
    "    return text\n",
    "\n",
    "def convert2unicode(f):\n",
    "    def tmp(text):\n",
    "        if not isinstance(text, unicode): text = text.decode('utf8')\n",
    "        return f(text)\n",
    "    return tmp\n",
    "\n",
    "def convert2lower(f):\n",
    "    def tmp(text):        \n",
    "        return f(text.lower())\n",
    "    return tmp\n",
    "\n",
    "#P.S. Декораторы могут усложнять отладку, так что от них вполне можно отказаться и воспользоваться copy-paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@convert2lower\n",
    "@convert2unicode\n",
    "def easy_tokenizer(text):\n",
    "    word = unicode()\n",
    "    for symbol in text:\n",
    "        if symbol.isalnum(): word += symbol\n",
    "        elif word:\n",
    "            yield word\n",
    "            word = unicode()\n",
    "    if word: yield word\n",
    "\n",
    "PYMORPHY_CACHE = {}\n",
    "MORPH = None\n",
    "#hint, чтобы установка pymorphy2 не была бы обязательной\n",
    "def get_lemmatizer():\n",
    "    import pymorphy2\n",
    "    global MORPH\n",
    "    if MORPH is None: MORPH = pymorphy2.MorphAnalyzer()\n",
    "    return MORPH\n",
    "\n",
    "@convert2lower\n",
    "@convert2unicode\n",
    "def pymorphy_tokenizer(text):\n",
    "    global PYMORPHY_CACHE\n",
    "    for word in easy_tokenizer(text):\n",
    "        word_hash = hash(word)\n",
    "        if word_hash not in PYMORPHY_CACHE:\n",
    "            PYMORPHY_CACHE[word_hash] = get_lemmatizer().parse(word)[0].normal_form            \n",
    "        yield PYMORPHY_CACHE[word_hash]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нужно разделить каждое предложение на токены (слова), при этом можно удалить пунктуацию, стоп-слова, выполнить стемминг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_words(sentence):\n",
    "    \"\"\"\n",
    "    Get words from sentence\n",
    "    \n",
    "    Perform normalization, remove punctuation, remove stop_words, etc...\n",
    "\n",
    "    Inputs:\n",
    "    - sentence: string - sentence text\n",
    "\n",
    "    Returns:\n",
    "    - list of strings\n",
    "    \"\"\"\n",
    "    sentence_terms = None\n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    tokens = []\n",
    "    sentence_terms = pymorphy_tokenizer(sentence)\n",
    "    for word in sentence_terms:\n",
    "        tokens.append(word)\n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob\n",
      "livingston\n",
      "the\n",
      "incoming\n",
      "speaker\n",
      "of\n",
      "the\n",
      "house\n",
      "took\n",
      "no\n",
      "public\n",
      "role\n",
      "friday\n",
      "as\n",
      "the\n",
      "debate\n",
      "unfolded\n",
      "on\n",
      "whether\n",
      "to\n",
      "impeach\n",
      "president\n",
      "clinton\n"
     ]
    }
   ],
   "source": [
    "words  = sentence_words(text[0])\n",
    "for word in words:\n",
    "    print ('{}'.format(word))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = list(())\n",
    "for txt in text:\n",
    "    words = sentence_words(txt)\n",
    "    sentences.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам необходима функция для подсчета tf слов в каждом предложении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_tf(sentences):\n",
    "    \"\"\"\n",
    "    Compute TF for each term in sentece for all sentences\n",
    "\n",
    "    Inputs:\n",
    "    - sentences: list of tokenized sentences\n",
    "\n",
    "    Returns:\n",
    "    - list of dicts of tf values\n",
    "    \"\"\"\n",
    "    tf_values = map(Counter, sentences)\n",
    "\n",
    "    tf_metrics = []\n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    for i, sentence in enumerate(sentences): \n",
    "        data = dict() \n",
    "        for word in sentence: \n",
    "            data.update({word : tf_values[i][word]/float(len(sentence))}) \n",
    "            tf_metrics.append(data) \n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "\n",
    "    return tf_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же нам необходима функция для подсчета IDF всех токенов из текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_idf(sentences):\n",
    "    idf_metrics = {}\n",
    "    sentences_count = len(sentences)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    all_tokens_set = set([item for sublist in sentences for item in sublist])\n",
    "    for tkn in all_tokens_set:\n",
    "        contains_token = map(lambda doc: tkn in doc, sentences)\n",
    "        idf_metrics[tkn] = 1 + np.log(sentences_count/(sum(contains_token)))\n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "    return idf_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы определить похожесть двух предложений, нам нужно использовать какую-то метрику похожести. Мы будем использовать модицифированное косинусное расстояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def singl_compute_tf(sentence):\n",
    "     for word in sentence: \n",
    "        data.update({word : tf_values[i][word]/float(len(sentence))}) \n",
    "        tf_metrics.append(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list = compute_tf(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043478260869565216"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_list[0][u'as']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'bob',\n",
       "  u'livingston',\n",
       "  u'the',\n",
       "  u'incoming',\n",
       "  u'speaker',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'house',\n",
       "  u'took',\n",
       "  u'no',\n",
       "  u'public',\n",
       "  u'role',\n",
       "  u'friday',\n",
       "  u'as',\n",
       "  u'the',\n",
       "  u'debate',\n",
       "  u'unfolded',\n",
       "  u'on',\n",
       "  u'whether',\n",
       "  u'to',\n",
       "  u'impeach',\n",
       "  u'president',\n",
       "  u'clinton'],\n",
       " [u'his',\n",
       "  u'previous',\n",
       "  u'24',\n",
       "  u'hours',\n",
       "  u'had',\n",
       "  u'been',\n",
       "  u'his',\n",
       "  u'most',\n",
       "  u'visible',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'month',\n",
       "  u'since',\n",
       "  u'his',\n",
       "  u'party',\n",
       "  u'nominated',\n",
       "  u'him',\n",
       "  u'as',\n",
       "  u'speaker',\n",
       "  u'and',\n",
       "  u'perhaps',\n",
       "  u'the',\n",
       "  u'most',\n",
       "  u'excruciating',\n",
       "  u'in',\n",
       "  u'his',\n",
       "  u'public',\n",
       "  u'career',\n",
       "  u'he',\n",
       "  u'spent',\n",
       "  u'most',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'day',\n",
       "  u'in',\n",
       "  u'a',\n",
       "  u'chaotic',\n",
       "  u'procedural',\n",
       "  u'wrangle',\n",
       "  u'over',\n",
       "  u'the',\n",
       "  u'terms',\n",
       "  u'of',\n",
       "  u'friday',\n",
       "  u's',\n",
       "  u'debate',\n",
       "  u'he',\n",
       "  u'ended',\n",
       "  u'it',\n",
       "  u'by',\n",
       "  u'telling',\n",
       "  u'his',\n",
       "  u'republican',\n",
       "  u'colleagues',\n",
       "  u'that',\n",
       "  u'he',\n",
       "  u'had',\n",
       "  u'had',\n",
       "  u'extramarital',\n",
       "  u'affairs',\n",
       "  u'during',\n",
       "  u'his',\n",
       "  u'20',\n",
       "  u'year',\n",
       "  u'tenure',\n",
       "  u'in',\n",
       "  u'congress'],\n",
       " [u'his',\n",
       "  u'disclosure',\n",
       "  u'followed',\n",
       "  u'an',\n",
       "  u'investigation',\n",
       "  u'by',\n",
       "  u'larry',\n",
       "  u'flynt',\n",
       "  u'publisher',\n",
       "  u'of',\n",
       "  u'hustler',\n",
       "  u'the',\n",
       "  u'sex',\n",
       "  u'magazine',\n",
       "  u'who',\n",
       "  u'said',\n",
       "  u'friday',\n",
       "  u'at',\n",
       "  u'a',\n",
       "  u'news',\n",
       "  u'conference',\n",
       "  u'in',\n",
       "  u'beverly',\n",
       "  u'hills',\n",
       "  u'calif'],\n",
       " [u'that',\n",
       "  u'his',\n",
       "  u'publication',\n",
       "  u'had',\n",
       "  u'learned',\n",
       "  u'that',\n",
       "  u'livingston',\n",
       "  u'had',\n",
       "  u'had',\n",
       "  u'adulterous',\n",
       "  u'affairs',\n",
       "  u'during',\n",
       "  u'the',\n",
       "  u'last',\n",
       "  u'10',\n",
       "  u'years'],\n",
       " [u'flynt',\n",
       "  u'said',\n",
       "  u'earlier',\n",
       "  u'this',\n",
       "  u'year',\n",
       "  u'that',\n",
       "  u'he',\n",
       "  u'wanted',\n",
       "  u'to',\n",
       "  u'expose',\n",
       "  u'the',\n",
       "  u'hypocrisy',\n",
       "  u'of',\n",
       "  u'those',\n",
       "  u'in',\n",
       "  u'washington',\n",
       "  u'who',\n",
       "  u'are',\n",
       "  u'investigating',\n",
       "  u'clinton',\n",
       "  u'and',\n",
       "  u'in',\n",
       "  u'october',\n",
       "  u'offered',\n",
       "  u'1',\n",
       "  u'million',\n",
       "  u'to',\n",
       "  u'anyone',\n",
       "  u'who',\n",
       "  u'could',\n",
       "  u'prove',\n",
       "  u'they',\n",
       "  u'had',\n",
       "  u'had',\n",
       "  u'affairs',\n",
       "  u'with',\n",
       "  u'members',\n",
       "  u'of',\n",
       "  u'congress'],\n",
       " [u'he',\n",
       "  u'said',\n",
       "  u'friday',\n",
       "  u'that',\n",
       "  u'this',\n",
       "  u'larger',\n",
       "  u'investigation',\n",
       "  u'to',\n",
       "  u'be',\n",
       "  u'published',\n",
       "  u'perhaps',\n",
       "  u'as',\n",
       "  u'soon',\n",
       "  u'as',\n",
       "  u'january',\n",
       "  u'would',\n",
       "  u'reveal',\n",
       "  u'what',\n",
       "  u'he',\n",
       "  u'described',\n",
       "  u'as',\n",
       "  u'indiscretions',\n",
       "  u'of',\n",
       "  u'several',\n",
       "  u'other',\n",
       "  u'republicans'],\n",
       " [u'he',\n",
       "  u'said',\n",
       "  u'he',\n",
       "  u'had',\n",
       "  u'no',\n",
       "  u'connection',\n",
       "  u'with',\n",
       "  u'the',\n",
       "  u'white',\n",
       "  u'house',\n",
       "  u'but',\n",
       "  u'that',\n",
       "  u'he',\n",
       "  u'had',\n",
       "  u'hired',\n",
       "  u'an',\n",
       "  u'investigative',\n",
       "  u'firm',\n",
       "  u'based',\n",
       "  u'in',\n",
       "  u'washington',\n",
       "  u'and',\n",
       "  u'made',\n",
       "  u'up',\n",
       "  u'of',\n",
       "  u'former',\n",
       "  u'employees',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'fbi',\n",
       "  u'and',\n",
       "  u'the',\n",
       "  u'cia'],\n",
       " [u'he',\n",
       "  u'would',\n",
       "  u'not',\n",
       "  u'confirm',\n",
       "  u'whether',\n",
       "  u'the',\n",
       "  u'firm',\n",
       "  u'is',\n",
       "  u'terry',\n",
       "  u'lenzner',\n",
       "  u's',\n",
       "  u'investigative',\n",
       "  u'group',\n",
       "  u'inc'],\n",
       " [u'which',\n",
       "  u'has',\n",
       "  u'done',\n",
       "  u'work',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'president',\n",
       "  u's',\n",
       "  u'private',\n",
       "  u'lawyers'],\n",
       " [u'livingston', u'was', u'unavailable', u'to', u'reporters', u'friday'],\n",
       " [u'he',\n",
       "  u'spent',\n",
       "  u'some',\n",
       "  u'time',\n",
       "  u'friday',\n",
       "  u'morning',\n",
       "  u'sprawled',\n",
       "  u'in',\n",
       "  u'a',\n",
       "  u'chair',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'back',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'house',\n",
       "  u'chamber',\n",
       "  u'listening',\n",
       "  u'to',\n",
       "  u'the',\n",
       "  u'debate',\n",
       "  u'over',\n",
       "  u'whether',\n",
       "  u'to',\n",
       "  u'impeach',\n",
       "  u'clinton',\n",
       "  u'for',\n",
       "  u'lying',\n",
       "  u'about',\n",
       "  u'his',\n",
       "  u'own',\n",
       "  u'sexual',\n",
       "  u'indiscretions'],\n",
       " [u'several',\n",
       "  u'colleagues',\n",
       "  u'knelt',\n",
       "  u'at',\n",
       "  u'livingston',\n",
       "  u's',\n",
       "  u'knee',\n",
       "  u'whispered',\n",
       "  u'to',\n",
       "  u'him',\n",
       "  u'and',\n",
       "  u'patted',\n",
       "  u'him',\n",
       "  u'on',\n",
       "  u'the',\n",
       "  u'back'],\n",
       " [u'he',\n",
       "  u'spent',\n",
       "  u'most',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'day',\n",
       "  u'in',\n",
       "  u'a',\n",
       "  u'private',\n",
       "  u'office',\n",
       "  u'off',\n",
       "  u'the',\n",
       "  u'chamber',\n",
       "  u'avoiding',\n",
       "  u'the',\n",
       "  u'gauntlet',\n",
       "  u'of',\n",
       "  u'reporters',\n",
       "  u'who',\n",
       "  u'lay',\n",
       "  u'in',\n",
       "  u'wait',\n",
       "  u'for',\n",
       "  u'him',\n",
       "  u'between',\n",
       "  u'the',\n",
       "  u'house',\n",
       "  u'and',\n",
       "  u'his',\n",
       "  u'regular',\n",
       "  u'office',\n",
       "  u'across',\n",
       "  u'the',\n",
       "  u'street'],\n",
       " [u'the',\n",
       "  u'only',\n",
       "  u'word',\n",
       "  u'out',\n",
       "  u'of',\n",
       "  u'his',\n",
       "  u'aides',\n",
       "  u'was',\n",
       "  u'that',\n",
       "  u'the',\n",
       "  u'navy',\n",
       "  u'had',\n",
       "  u'awarded',\n",
       "  u'contracts',\n",
       "  u'worth',\n",
       "  u'millions',\n",
       "  u'of',\n",
       "  u'dollars',\n",
       "  u'for',\n",
       "  u'ships',\n",
       "  u'to',\n",
       "  u'be',\n",
       "  u'built',\n",
       "  u'in',\n",
       "  u'his',\n",
       "  u'louisiana',\n",
       "  u'district',\n",
       "  u'at',\n",
       "  u'the',\n",
       "  u'avondale',\n",
       "  u'shipyards'],\n",
       " [u'during',\n",
       "  u'friday',\n",
       "  u's',\n",
       "  u'debate',\n",
       "  u'a',\n",
       "  u'handful',\n",
       "  u'of',\n",
       "  u'democrats',\n",
       "  u'made',\n",
       "  u'only',\n",
       "  u'oblique',\n",
       "  u'allusions',\n",
       "  u'to',\n",
       "  u'human',\n",
       "  u'failures'],\n",
       " [u'for', u'example', u'rep'],\n",
       " [u'john', u'lewis', u'd', u'ga'],\n",
       " [u'said',\n",
       "  u'let',\n",
       "  u'he',\n",
       "  u'that',\n",
       "  u'has',\n",
       "  u'no',\n",
       "  u'sin',\n",
       "  u'cast',\n",
       "  u'the',\n",
       "  u'first',\n",
       "  u'stone'],\n",
       " [u'who',\n",
       "  u'who',\n",
       "  u'among',\n",
       "  u'us',\n",
       "  u'has',\n",
       "  u'not',\n",
       "  u'sinned',\n",
       "  u'but',\n",
       "  u'no',\n",
       "  u'one',\n",
       "  u'said',\n",
       "  u'that',\n",
       "  u'livingston',\n",
       "  u's',\n",
       "  u'disclosure',\n",
       "  u'or',\n",
       "  u'the',\n",
       "  u'mild',\n",
       "  u'democratic',\n",
       "  u'attempts',\n",
       "  u'to',\n",
       "  u'exploit',\n",
       "  u'it',\n",
       "  u'would',\n",
       "  u'influence',\n",
       "  u'their',\n",
       "  u'votes',\n",
       "  u'on',\n",
       "  u'impeachment'],\n",
       " [u'rather',\n",
       "  u'on',\n",
       "  u'the',\n",
       "  u'house',\n",
       "  u'floor',\n",
       "  u'and',\n",
       "  u'in',\n",
       "  u'hallway',\n",
       "  u'chitchat',\n",
       "  u'livingston',\n",
       "  u's',\n",
       "  u'conduct',\n",
       "  u'seemed',\n",
       "  u'to',\n",
       "  u'be',\n",
       "  u'the',\n",
       "  u'last',\n",
       "  u'thing',\n",
       "  u'that',\n",
       "  u'either',\n",
       "  u'republicans',\n",
       "  u'or',\n",
       "  u'democrats',\n",
       "  u'wanted',\n",
       "  u'to',\n",
       "  u'talk',\n",
       "  u'about'],\n",
       " [u'bob',\n",
       "  u'livingston',\n",
       "  u'is',\n",
       "  u'a',\n",
       "  u'first',\n",
       "  u'rate',\n",
       "  u'human',\n",
       "  u'being',\n",
       "  u'said',\n",
       "  u'rep'],\n",
       " [u'david', u'obey', u'd', u'wis'],\n",
       " [u'who',\n",
       "  u'has',\n",
       "  u'worked',\n",
       "  u'closely',\n",
       "  u'and',\n",
       "  u'sparred',\n",
       "  u'with',\n",
       "  u'livingston',\n",
       "  u'on',\n",
       "  u'the',\n",
       "  u'appropriations',\n",
       "  u'committee',\n",
       "  u'in',\n",
       "  u'an',\n",
       "  u'interview'],\n",
       " [u'i',\n",
       "  u'will',\n",
       "  u'repeat',\n",
       "  u'what',\n",
       "  u'the',\n",
       "  u'nuns',\n",
       "  u'taught',\n",
       "  u'me',\n",
       "  u'at',\n",
       "  u'st'],\n",
       " [u'james',\n",
       "  u'a',\n",
       "  u'long',\n",
       "  u'time',\n",
       "  u'ago',\n",
       "  u'we',\n",
       "  u'would',\n",
       "  u'all',\n",
       "  u'be',\n",
       "  u'a',\n",
       "  u'hell',\n",
       "  u'of',\n",
       "  u'a',\n",
       "  u'lot',\n",
       "  u'better',\n",
       "  u'off',\n",
       "  u'looking',\n",
       "  u'after',\n",
       "  u'our',\n",
       "  u'own',\n",
       "  u'souls',\n",
       "  u'rather',\n",
       "  u'than',\n",
       "  u'trying',\n",
       "  u'to',\n",
       "  u'evaluate',\n",
       "  u'somebody',\n",
       "  u'else',\n",
       "  u's'],\n",
       " [u'none',\n",
       "  u'of',\n",
       "  u'us',\n",
       "  u'have',\n",
       "  u'any',\n",
       "  u'business',\n",
       "  u'even',\n",
       "  u'having',\n",
       "  u'an',\n",
       "  u'opinion',\n",
       "  u'on',\n",
       "  u'it'],\n",
       " [u'even',\n",
       "  u'conservative',\n",
       "  u'republicans',\n",
       "  u'seemed',\n",
       "  u'ready',\n",
       "  u'to',\n",
       "  u'overlook',\n",
       "  u'the',\n",
       "  u'disclosure'],\n",
       " [u'we',\n",
       "  u're',\n",
       "  u'not',\n",
       "  u'going',\n",
       "  u'to',\n",
       "  u'say',\n",
       "  u'bob',\n",
       "  u'you',\n",
       "  u'can',\n",
       "  u't',\n",
       "  u'be',\n",
       "  u'speaker',\n",
       "  u'because',\n",
       "  u'you',\n",
       "  u'violated',\n",
       "  u'your',\n",
       "  u'vows',\n",
       "  u'with',\n",
       "  u'your',\n",
       "  u'wife',\n",
       "  u'said',\n",
       "  u'rep'],\n",
       " [u'lindsey', u'graham', u'r', u's'],\n",
       " [u'c'],\n",
       " [u'like',\n",
       "  u'many',\n",
       "  u'including',\n",
       "  u'livingston',\n",
       "  u'graham',\n",
       "  u'distinguished',\n",
       "  u'livingston',\n",
       "  u's',\n",
       "  u'conduct',\n",
       "  u'from',\n",
       "  u'clinton',\n",
       "  u's',\n",
       "  u'by',\n",
       "  u'saying',\n",
       "  u'that',\n",
       "  u'the',\n",
       "  u'president',\n",
       "  u'had',\n",
       "  u'trampled',\n",
       "  u'on',\n",
       "  u'the',\n",
       "  u'legal',\n",
       "  u'system',\n",
       "  u'whereas',\n",
       "  u'livingston',\n",
       "  u's',\n",
       "  u'behavior',\n",
       "  u'was',\n",
       "  u'strictly',\n",
       "  u'private'],\n",
       " [u'despite',\n",
       "  u'flynt',\n",
       "  u's',\n",
       "  u'claims',\n",
       "  u'many',\n",
       "  u'republicans',\n",
       "  u'blamed',\n",
       "  u'the',\n",
       "  u'clinton',\n",
       "  u'administration',\n",
       "  u'for',\n",
       "  u'smearing',\n",
       "  u'livingston',\n",
       "  u'although',\n",
       "  u'they',\n",
       "  u'offered',\n",
       "  u'no',\n",
       "  u'evidence'],\n",
       " [u'this',\n",
       "  u'isn',\n",
       "  u't',\n",
       "  u'just',\n",
       "  u'happening',\n",
       "  u'on',\n",
       "  u'its',\n",
       "  u'own',\n",
       "  u'said',\n",
       "  u'rep'],\n",
       " [u'dana', u'rohrabacher', u'r', u'calif'],\n",
       " []]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(sentence1, sentence2, tf1, tf2, idf_metrics):\n",
    "    \"\"\"\n",
    "    Compute idf-modified-cosine distance between two sentences.\n",
    "    \n",
    "    Inputs:\n",
    "    - sentence1: list of terms of sentence 1\n",
    "    - sentence2: list of terms of sentence 2\n",
    "    - tf1: dict of term frequencies of sentence 1\n",
    "    - tf2: dict of term frequencies of sentence 2\n",
    "    - idf_metrics: list of inverted document frequencies\n",
    "\n",
    "    Returns:\n",
    "    - modified cosine similarity\n",
    "    \"\"\"\n",
    "    similarity = 0.0\n",
    "    \n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    a = set(sentence1)\n",
    "    b = set(sentence2)\n",
    "    c = a.intersection(b)\n",
    "    \n",
    "    numerator = np.sum((tf1[word]*tf2[word]) * np.square(idf_metrics[word]) for word in c)\n",
    "\n",
    "    denominator=np.sqrt(np.sum(np.square(tf1[word1]*idf_metrics[word1]) for word1 in a))*\\\n",
    "                np.sqrt(np.sum(np.square(tf2[word2]*idf_metrics[word2]) for word2 in b))\n",
    "        \n",
    "    \n",
    "    \n",
    "    similarity = numerator/float(denominator)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13146040393268776"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sentences[0], sentences[1], compute_tf([sentences[0]])[0], compute_tf([sentences[1]])[0], compute_idf(sentences) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим матрицу размером NxN, где N - это количество предложений. В каждой ячейки i,j - будем записывать похожесть i-го предложения на j-ое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(sentences, threshold = 0.01, tf_metrics = 'cosine', idf_metrics = 'cosine'):\n",
    "    \"\"\"\n",
    "    Creates matrix of shape |sentences|×|sentences|.\n",
    "    \n",
    "    Inputs:\n",
    "    - sentences: list of sentences\n",
    "    - threshold: threshold value for selecting edges\n",
    "    - tf_metrics: list of TF metrics for each sentence\n",
    "    - idf_metrics: list of inverted document frequencies\n",
    "\n",
    "    Returns:\n",
    "    - matrix of similarities\n",
    "    \"\"\"\n",
    "    sentences_count = len(sentences)-1\n",
    "    matrix = np.zeros((sentences_count, sentences_count))\n",
    "    degrees = np.zeros((sentences_count, ))\n",
    "    \n",
    "    idf_metrics = compute_idf(sentences)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    for i in range(sentences_count):\n",
    "        for j in range(sentences_count):\n",
    "            temp_value = cosine_similarity(sentences[i], \n",
    "                                         sentences[j],  \n",
    "                                         compute_tf([sentences[i]])[0], \n",
    "                                         compute_tf([sentences[j]])[0], \n",
    "                                         idf_metrics)\n",
    "            if temp_value<threshold:\n",
    "                matrix[i][j] = 0\n",
    "            else:\n",
    "                matrix[i][j] = temp_value\n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = create_matrix(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.1314604 ,  0.04514347, ...,  0.10283431,\n",
       "         0.03120173,  0.        ],\n",
       "       [ 0.1314604 ,  1.        ,  0.14443974, ...,  0.01516118,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.04514347,  0.14443974,  1.        , ...,  0.04402928,\n",
       "         0.02039254,  0.0957373 ],\n",
       "       ..., \n",
       "       [ 0.10283431,  0.01516118,  0.04402928, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.03120173,  0.        ,  0.02039254, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.0957373 , ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем power-метод:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def power_method(matrix, epsilon):\n",
    "    \"\"\"\n",
    "    Perform Power-method.\n",
    "    \n",
    "    Inputs:\n",
    "    - matrix: matrix of sentences similarities\n",
    "    - epsilon: stop when values changes less then epsilon\n",
    "    - tf_metrics: list of TF metrics for each sentence\n",
    "    - idf_metrics: list of inverted document frequencies\n",
    "\n",
    "    Returns:\n",
    "    - vector of sentence's importancies\n",
    "    \"\"\"\n",
    "    transposed_matrix = matrix.T\n",
    "    sentences_count = len(matrix)\n",
    "    p_vector = np.array([1.0 / sentences_count] * sentences_count)\n",
    "    delta = 1.0\n",
    "\n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    \n",
    "    while (delta>epsilon):\n",
    "        p_prev = p_vector\n",
    "        p_vector = transposed_matrix.dot(p_prev)\n",
    "        delta = (p_vector - p_prev).dot(p_vector - p_prev)\n",
    "    \n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "\n",
    "    return p_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vec = power_method(A, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0956048 ,  0.10402652,  0.07800694,  0.07192362,  0.09295337,\n",
       "        0.07672031,  0.09774602,  0.06059245,  0.06016124,  0.06479622,\n",
       "        0.1002883 ,  0.07255102,  0.09374867,  0.08061369,  0.07129237,\n",
       "        0.0494492 ,  0.03502812,  0.06630681,  0.08296964,  0.09210437,\n",
       "        0.07038013,  0.03502812,  0.07299352,  0.03697844,  0.0600822 ,\n",
       "        0.0495949 ,  0.05293147,  0.0540338 ,  0.05133441,  0.02941176,\n",
       "        0.08899941,  0.06744371,  0.05504874,  0.03917764])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 16, 21, 23, 33, 15, 25, 28, 26, 27, 32, 24,  8,  7,  9, 17, 31,\n",
       "       20, 14,  3, 11, 22,  5,  2, 13, 18, 30, 19,  4, 12,  0,  6, 10])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(p_vec)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По полученым оценкам важности каждого предложения выделим k-самых важных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_sentences(sentences, values, k):\n",
    "    \"\"\"\n",
    "    Get K top rated sentences from all sentences.\n",
    "    \n",
    "    Inputs:\n",
    "    - sentences: list of sentences\n",
    "    - values: list of computed sentence importancies\n",
    "    - k: number of sentences to extract\n",
    "\n",
    "    Returns:\n",
    "    - list of sentences\n",
    "    \"\"\"\n",
    "    top_sentences = []\n",
    "    \n",
    "    #############################################################################\n",
    "    #                                 YOUR CODE                                 #\n",
    "    #############################################################################\n",
    "    dictionary = defaultdict()\n",
    "    for imp,sentence in zip(values,sentences):\n",
    "        dictionary[sentence] = imp\n",
    "        \n",
    "    top_sentences = sorted(dictionary, key=dictionary.get, reverse=True)[:k]\n",
    "    \n",
    "    #############################################################################\n",
    "    #                              END OF YOUR CODE                             #\n",
    "    #############################################################################\n",
    "    \n",
    "    return top_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим саммари:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' His disclosure followed an investigation by Larry Flynt, publisher of Hustler, the sex magazine, who said Friday at a news conference in Beverly Hills, Calif', \", which has done work for the president's private lawyers\", ' He spent most of the day in a private office off the chamber, avoiding the gauntlet of reporters who lay in wait for him between the House and his regular office across the street']\n",
      "[\"'' Presidential resignation was in order, he continued, and then came the shouts of ``You resign! You resign!'' And as Livingston closed the circle on his career, he stunned the place into a collective breath of disbelief and somehow almost threatened to reduce the dark historic issue before the House _ the impeachment of the president _ into a matter of anticlimax\", ' Shockingly, stunningly, Livingston did just that', ' They had to stand, almost staggering to their feet, to join the Republicans in a prolonged, emotional ovation for Livingston and his undeniable self-sacrifice']\n",
      "[' Through cooperation, they can guide the Senate toward a punishment that fixes Clinton in history as a president who lied under oath, but avoids the taint of partisan vengeance associated with the House impeachment vote', \" The result is that after Saturday's expected impeachment vote, after Livingston's unexpected announcement, the mission of the Senate remains the same\", \" The Senate's historic reputation for prudence requires it to find appropriate punishment for a personally weak president who has damaged the rule of law, but not threatened the stability of the government\"]\n",
      "[\"'' Rep\", ' The impeachment, said Rep', ' There were hardly enough shorthand terms or split screens to cover the activity']\n",
      "[' Ordinarily one would feel sorry for Livingston', ' Just eradicate us and start from scratch', ' In an incredibly unseemly display, Trent Lott, the majority leader, and former Bush national security adviser Brent Scowcroft and Bush Secretary of State Lawrence Eagleburger chimed in on the attack']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romandegtyarev/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" Livingston's decision was said to be driven in part by the anger of a group of about a dozen conservatives in his party who were disillusioned that he had withheld news of his affairs from them\", \"'' As the leaders tried Saturday to hold the party together on and off the House floor, most Republicans stuck to their prepared scripts on the floor in favor of impeaching the president\", \", who admitted to his own adulterous affair earlier this year, said after Livingston's resignation: ``Those of us who are sinners must feel wretched today\"]\n",
      "[\" ``It breaks your heart because we're all subject to human frailties,'' said Asa Hutchinson, R-Ark\", \"'' ``During my 33-year marriage to my wife, Bonnie, I have on occasion strayed from my marriage, and doing so nearly cost me my marriage and family,'' Livingston said in his brief prepared statement\", \" ``We've got a duty to do under the Constitution\"]\n",
      "[' At a time when events in the world and the challenges at home demand that we stand united, censure is the one solution that can bring us together', ' The GOP can no longer conceal that it is a party of extremists, of right-wing absolutists, a party out of step with the political and cultural orientation of most Americans', \"'' David Bonior, the Democratic whip, said: ``This is wrong\"]\n",
      "[' Wrong', ' Twice wrong', ' Rep']\n",
      "[\" Through the efforts of Kenneth Starr, the independent counsel under the law enacted in the wake of Watergate, the investigation spread to examine Clinton's affair with a White House intern\", \" ``Justice is so important to the most humble among us,'' Hyde said\", \" Watts of Oklahoma, newly elected as chairman of the Republican caucus, said: ``What's popular isn't always right\"]\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "    sentences = get_sentences(document)\n",
    "    sentences_tokenized = [sentence_words(x) for x in sentences]\n",
    "    tf_metrics = compute_tf(sentences_tokenized)\n",
    "    idf_metrics = compute_idf(sentences_tokenized)\n",
    "    \n",
    "    matrix = create_matrix(sentences_tokenized, 0.3, tf_metrics, idf_metrics)\n",
    "    sentence_values = power_method(matrix, 0.001)\n",
    "    \n",
    "    print(get_top_sentences(sentences, sentence_values, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
